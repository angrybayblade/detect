{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "from collections import Counter\n",
    "from plotly import express as ex\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from glob import glob\n",
    "from os import path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = path.abspath(\"./datasets/BCCD/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for p in glob(path.abspath(f\"{PATH}/annotations/*.xml\")):\n",
    "    try:\n",
    "        parse = ET.parse(p)\n",
    "    except:\n",
    "        continue\n",
    "    objects = [[i.tag,i.text] for i in parse.iter()]\n",
    "    image = {i:j for i ,j in objects[:11]}\n",
    "    boxes = []\n",
    "    for ob,name,pose,_,__,___,xmin,ymin,xmax,ymax in np.array(objects[11:]).reshape(-1,20)[:,1::2]:\n",
    "        boxes.append(dict(\n",
    "            name=name,\n",
    "            xmin=int(xmin),\n",
    "            ymin=int(ymin),\n",
    "            xmax=int(xmax),\n",
    "            ymax=int(ymax),\n",
    "        ))    \n",
    "    image['boxes'] = boxes\n",
    "    image['filename'] = path.abspath(f\"{PATH}/images/{image['filename']}\")\n",
    "    [image.pop(i) for i in ['annotation','path','folder','source','size','database','segmented','depth']];\n",
    "    data.append(image)\n",
    "    \n",
    "    \n",
    "rows = []\n",
    "\n",
    "for row in data.copy():\n",
    "    for box in row['boxes']:\n",
    "        box['filename'] = row['filename']\n",
    "        box['width'] = row['width']\n",
    "        box['height'] = row['height']\n",
    "        box['class'] = box.pop('name')\n",
    "        rows.append(box)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.DataFrame(rows)[['filename','width','height','class','xmin','ymin','xmax','ymax']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['xmin'],train['xmax'] = train['xmin'] / 640,train['xmax'] / 640\n",
    "train['ymin'],train['ymax'] = train['ymin'] / 480,train['ymax'] / 480"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['h'] = train.ymax - train.ymin\n",
    "train['w'] = train.xmax - train.xmin\n",
    "\n",
    "train['y'] = train.ymin + (train.h / 2)\n",
    "train['x'] = train.xmin + (train.w / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JSON(object):\n",
    "    \"\"\"\n",
    "    Helper Class For Mapping JSON vars to Objects\n",
    "    \"\"\"\n",
    "    def __init__(self,data=dict(),inner=False):\n",
    "        for key in data:\n",
    "            if type(data[key]) == dict:\n",
    "                self.__dict__[key] = JSON(data[key],inner=True)\n",
    "            else:\n",
    "                self.__dict__[key] = data[key]\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__dict__.__str__()\n",
    "    \n",
    "    def __str__(self):\n",
    "        return self.__dict__.__str__()\n",
    "    \n",
    "    def __getitem__(self,key):\n",
    "        return self.__dict__[key]\n",
    "    \n",
    "    def __setitem__(self,key,value):\n",
    "        self.__dict__[key] = value\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for key in self.__dict__:\n",
    "            if type(self.__dict__[key]) == JSON:\n",
    "                yield key, self.__dict__[key]()\n",
    "            else:\n",
    "                yield key, self.__dict__[key]\n",
    "        \n",
    "    def __call__(self,):\n",
    "        return {i:j for i,j in  self.__iter__()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['class'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "grouped = train.groupby(by='filename')\n",
    "\n",
    "for i in train.filename.unique():\n",
    "    group = grouped.get_group(i)[['class','xmin','ymin','xmax','ymax','x','y','h','w']]\n",
    "#     group = group[group['class']]#.query('h > 0.4 and w > 0.3')\n",
    "    group = group.T.to_dict().values()\n",
    "    boxes = [JSON(i) for i in group]\n",
    "    if len(boxes):\n",
    "        data.append(JSON({\n",
    "            'filename':i,\n",
    "            'boxes':boxes\n",
    "        }))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 384"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = data[np.random.randint(len(data))]\n",
    "\n",
    "img = cv2.imread(image['filename'])\n",
    "img = cv2.resize(img,(IMG_SIZE,IMG_SIZE))\n",
    "\n",
    "for box in image['boxes']:\n",
    "    img = cv2.putText(img,box['class'],(int(box['xmin']*512),int(box['ymin']*512)-5),cv2.FONT_HERSHEY_SIMPLEX,0.4,(255,255,255))\n",
    "    img = cv2.rectangle(\n",
    "            img,\n",
    "            (int(box.xmin*IMG_SIZE),int(box.ymin*IMG_SIZE)),\n",
    "            (int(box.xmax*IMG_SIZE),int(box.ymax*IMG_SIZE)),\n",
    "            (255,0,0),\n",
    "            1\n",
    "        )\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.array([cv2.resize(cv2.imread(i['filename']),(IMG_SIZE,IMG_SIZE)) for i in data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = images.astype(np.float32) / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hw = ((train[['h','w']].copy()*IMG_SIZE).astype(np.uint16) / 64)*64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex.scatter(data_frame=hw,x='w',y='h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = np.random.randint(len(images))\n",
    "\n",
    "img = images[i].copy()\n",
    "dat = data[i]\n",
    "\n",
    "for d in dat.boxes:\n",
    "    img = cv2.rectangle(\n",
    "                    img,\n",
    "                    (int(d.xmin*IMG_SIZE),int(d.ymin*IMG_SIZE)),\n",
    "                    (int(d.xmax*IMG_SIZE),int(d.ymax*IMG_SIZE)),\n",
    "                    (255,0,0),\n",
    "                    1\n",
    "                )\n",
    "    \n",
    "    img = cv2.circle(\n",
    "                    img,\n",
    "                    (int(d.x*IMG_SIZE),int(d.y*IMG_SIZE)),\n",
    "                    1,\n",
    "                    (0,0,0),\n",
    "                    -1\n",
    "                )\n",
    "\n",
    "plt.figure(figsize=(12,12\n",
    "                   ))\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BoxGrid(object):\n",
    "    \"\"\"\n",
    "    Encodes Box\n",
    "    \"\"\"\n",
    "    def __init__(self,low,high):\n",
    "        self.low = low\n",
    "        self.high = high\n",
    "        self.repr = f\"\"\"\n",
    "BoxGrid(\n",
    "    low={self.low},\n",
    "    high={self.high}\n",
    ")\n",
    "        \"\"\"\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.repr\n",
    "    \n",
    "    def encode(self,h,w):\n",
    "        return h/self.high,w/self.high\n",
    "    \n",
    "    def get_pair(self,y,x,h,w):\n",
    "        h = int(h*self.high)\n",
    "        w = int(w*self.high)\n",
    "        return (x - (h//2),y - (h//2)),(x + (h//2),y + (h//2))\n",
    "    \n",
    "    def decode(self,):\n",
    "        pass\n",
    "    \n",
    "    def encodeBatch(self,):\n",
    "        pass\n",
    "    \n",
    "    def decodeBatch(self,):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnchorGrid(object):\n",
    "    \n",
    "    def __init__(self,resize_factor,k,image_size,box_gen):\n",
    "        \n",
    "        self.k = k\n",
    "        self.resize_factor = resize_factor\n",
    "        self.image_size = image_size\n",
    "        self.grid_size = image_size // resize_factor\n",
    "        self.box_gen = BoxGrid(**box_gen)\n",
    "        self.length = self.grid_size*self.grid_size*self.k\n",
    "        \n",
    "        \n",
    "        self.repr = f\"\"\"\n",
    "AnchorGrid (\n",
    "    resize_factor={self.resize_factor},\n",
    "    k={self.k},\n",
    "    image_size={self.image_size},\n",
    "    grid_size={self.grid_size}\n",
    ")\"\"\"\n",
    "        \n",
    "    def __repr__(self,):\n",
    "        return self.repr\n",
    "                \n",
    "    def __call__(self,data):\n",
    "        \"\"\"\n",
    "        Returns : encoded_prob,encoded_box\n",
    "        \"\"\"\n",
    "        box = np.zeros((self.grid_size,self.grid_size,self.k,4))\n",
    "        prob_0 = np.zeros((self.grid_size,self.grid_size,self.k,1))\n",
    "        prob_1 = np.ones((self.grid_size,self.grid_size,self.k,1))\n",
    "        prob = np.concatenate((prob_1,prob_0),axis=3)        \n",
    "        \n",
    "        data = data[np.logical_and(np.all(data[:,2:] <= self.box_gen.high,axis=1), np.any(data[:,2:] > self.box_gen.low,axis=1))]\n",
    "        _counter = Counter()\n",
    "\n",
    "        for y,x,h,w in data:\n",
    "            Ox = int(x // self.resize_factor) \n",
    "            Oy = int(y // self.resize_factor) \n",
    "\n",
    "            if Ox == self.grid_size or Oy == self.grid_size:\n",
    "                continue\n",
    "\n",
    "            x = (x - (Ox*self.resize_factor)) / self.resize_factor\n",
    "            y = (y - (Oy*self.resize_factor)) / self.resize_factor\n",
    "            \n",
    "            h,w = self.box_gen.encode(h,w)\n",
    "                        \n",
    "            Oi = _counter[f\"{Oy}x{Ox}\"]\n",
    "            \n",
    "            box[Oy,Ox,Oi,:] = [y,x,h,w]\n",
    "            prob[Oy,Ox,Oi,:] = [0,1]\n",
    "            \n",
    "            _counter[f\"{Oy}x{Ox}\"] += 1\n",
    "\n",
    "        prob,box =  prob.reshape(-1,self.k,2),box.reshape(-1,self.k,4)\n",
    "        return prob.reshape(-1,2),box.reshape(-1,4)\n",
    "    \n",
    "    def encode(self,data):\n",
    "        return self.__call__(data)\n",
    "    \n",
    "    def decode(self,prob,boxes,thresh=0.9):\n",
    "        prob = prob.reshape(-1,self.k,1).reshape(self.grid_size,self.grid_size,self.k).copy()\n",
    "        boxes = boxes.reshape(-1,self.k,4).reshape(self.grid_size,self.grid_size,self.k,4).copy()\n",
    "        \n",
    "        mask = prob > thresh\n",
    "                        \n",
    "        boxes[:,:,:,:2] = ((boxes[:,:,:,:2] * self.resize_factor) + self.grid_decode).astype(int) - (self.resize_factor // 2)\n",
    "        boxes = boxes[mask]\n",
    "        boxes[:,2:] = boxes[:,2:] * self.box_gen.high\n",
    "        \n",
    "        return boxes.astype(int)\n",
    "        \n",
    "    def generate(self,ret=False):\n",
    "        xx,yy = np.meshgrid(np.arange(self.grid_size),np.arange(self.grid_size))\n",
    "        xx,yy = np.reshape(xx,(self.grid_size,self.grid_size,1)),np.reshape(yy,(self.grid_size,self.grid_size,1))\n",
    "        \n",
    "        self.reference = np.concatenate((yy,xx),axis=-1)\n",
    "        self.grid = self.reference.copy() * self.resize_factor\n",
    "        self.grid += self.resize_factor // 2\n",
    "        self.grid_decode = self.grid.copy().reshape(self.grid_size,self.grid_size,1,2).repeat(self.k,axis=2)\n",
    "        \n",
    "        if ret:\n",
    "            return self.grid.copy(),self.reference.copy()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnchorLayer(object):\n",
    "    \"\"\"\n",
    "    Encode Various Sizes Of FPNS\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,img_size,config,):\n",
    "        self.img_size = img_size\n",
    "        self.config = config\n",
    "        \n",
    "        for cfg in config:\n",
    "            self.__dict__[f\"ANCHOR_{cfg['name']}\"] = AnchorGrid(**cfg['anchor_grid'])\n",
    "            self.__dict__[f\"ANCHOR_{cfg['name']}\"].generate()\n",
    "        \n",
    "        self.ANCHORS = [i for (i,j) in self.__dict__.items() if \"ANCHOR_\" in i]\n",
    "        \n",
    "    def __repr__(self,):\n",
    "        return self.config.__repr__()\n",
    "    \n",
    "    def __call__(self,data):\n",
    "        \"\"\"\n",
    "        Returns : encoded_prob,encoded_box\n",
    "        \"\"\"\n",
    "        boxt = np.round(np.array([[b.y,b.x,b.h,b.w] for b in data.boxes])*self.img_size).astype(np.float32)\n",
    "        boxt = pd.DataFrame(boxt,columns=['y','x','h','w']).sort_values(by=['y','x','h','w']).values\n",
    "\n",
    "        prob,box = [],[]\n",
    "        \n",
    "        for anchor in self.ANCHORS:\n",
    "            p,b = self.__dict__[anchor](boxt)\n",
    "            prob.append(p)\n",
    "            box.append(b)\n",
    "            \n",
    "        prob = np.concatenate(prob,axis=0)\n",
    "        box = np.concatenate(box,axis=0)\n",
    "            \n",
    "        return prob,box\n",
    "    \n",
    "    def encode(self,data):\n",
    "        return self.__call__(data)\n",
    "    \n",
    "    def decode(self,prob,boxes,thresh=0.9):\n",
    "        prob = prob.reshape(-1,2).argmax(axis=1)\n",
    "        boxes = boxes.reshape(-1,4)\n",
    "        \n",
    "        last = 0\n",
    "        ret_boxes = []\n",
    "        for anchor in self.ANCHORS:\n",
    "            index = self.__dict__[anchor].length\n",
    "            batch_ = (prob[last:last+index].copy(),boxes[last:last+index].copy())\n",
    "            batch = self.__dict__[anchor].decode(*batch_,thresh=thresh)\n",
    "            last = last+index\n",
    "            ret_boxes.append(batch)\n",
    "                       \n",
    "        return np.concatenate(ret_boxes,axis=0).astype(np.uint32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_config = {\n",
    "    \"img_size\":IMG_SIZE,\n",
    "    \"config\":[\n",
    "        {\n",
    "            \"anchor_grid\":{\n",
    "                \"resize_factor\":32,\n",
    "                \"k\":3,\n",
    "                \"image_size\":IMG_SIZE,\n",
    "                \"box_gen\":{\n",
    "                    \"low\":8,\n",
    "                    \"high\":64\n",
    "                }\n",
    "            },\n",
    "            \"name\":\"FPN0\"\n",
    "        },\n",
    "        {\n",
    "            \"anchor_grid\":{\n",
    "                \"resize_factor\":64,\n",
    "                \"k\":4,\n",
    "                \"image_size\":IMG_SIZE,\n",
    "                \"box_gen\":{\n",
    "                    \"low\":64,\n",
    "                    \"high\":128\n",
    "                }\n",
    "            },\n",
    "            \"name\":\"FPN1\"\n",
    "        },\n",
    "        {\n",
    "            \"anchor_grid\":{\n",
    "                \"resize_factor\":128,\n",
    "                \"k\":3,\n",
    "                \"image_size\":IMG_SIZE,\n",
    "                \"box_gen\":{\n",
    "                    \"low\":128,\n",
    "                    \"high\":256\n",
    "                }\n",
    "            },\n",
    "            \"name\":\"FPN2\"\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchors = AnchorLayer(**anchor_config)\n",
    "prob_,box_ = anchors(data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchors.ANCHOR_FPN1.length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = np.random.randint(0,len(images))\n",
    "\n",
    "img = images[i].copy()\n",
    "prob_,box_ = anchors(data[i])\n",
    "decoded = anchors.decode(prob_,box_)\n",
    "\n",
    "for y,x,h,w in decoded:\n",
    "    img = cv2.rectangle(img,(x-(w//2),y-(h//2)),(x+(w//2),y+(h//2)),(255,0,0),1)\n",
    "\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob,y_box = [],[]\n",
    "\n",
    "\n",
    "for d in data:\n",
    "    p,b = anchors(d)\n",
    "    y_prob.append(p)\n",
    "    y_box.append(b)\n",
    "    \n",
    "y_prob,y_box = np.array(y_prob),np.array(y_box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = np.random.randint(0,len(images))\n",
    "\n",
    "img = images[i].copy()\n",
    "prob_ = y_prob[i].copy()\n",
    "box_ = y_box[i].copy()\n",
    "\n",
    "decoded = anchors.decode(prob_,box_)\n",
    "\n",
    "\n",
    "for y,x,h,w in decoded:\n",
    "    img = cv2.rectangle(img,(x-(w//2),y-(h//2)),(x+(w//2),y+(h//2)),(255,0,0),1)\n",
    "\n",
    "fig = plt.figure(figsize=(12,12))\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_index = set(np.random.randint(0,len(images),(68,)))\n",
    "train_index = set(np.arange(0,len(images)))\n",
    "\n",
    "train_index = list(train_index.difference(test_index))\n",
    "test_index = list(test_index)\n",
    "\n",
    "len(train_index),len(test_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,LearningRateScheduler,Callback,ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_inp = Input(shape=(IMG_SIZE,IMG_SIZE,3))\n",
    "\n",
    "\n",
    "def block(_in,filters,ksize,name,pool=False):\n",
    "    aconv0 = Conv2D(filters,ksize,activation=\"relu\",padding=\"same\",name=f\"{name}_conv0\")(_in)\n",
    "    aconv1 = Conv2D(filters,ksize,activation=\"relu\",padding=\"same\",name=f\"{name}_conv1\")(aconv0)\n",
    "    aconv2 = Conv2D(filters,ksize,activation=\"relu\",padding=\"same\",name=f\"{name}_conv2\")(aconv1)\n",
    "    aconv3 = Conv2D(filters,ksize,activation=\"relu\",padding=\"same\",name=f\"{name}_conv3\")(aconv2)\n",
    "    aout = BatchNormalization(name=f\"{name}_norm\")(concatenate([aconv0,aconv1,aconv2,aconv3],name=f\"{name}_conc\"))\n",
    "    \n",
    "    if pool:\n",
    "        aout = MaxPool2D(name=f\"{name}_pool\")(aout)\n",
    "    return aout\n",
    "\n",
    "\n",
    "def out(_in,k,name):\n",
    "    prob = Conv2D(k*2,1,padding=\"same\",name=f\"prob_conv_{name}\")(_in)\n",
    "    prob = BatchNormalization(name=f\"prob_norm_{name}\")(prob)\n",
    "    prob = Activation(\"sigmoid\",name=f\"prob_out_{name}\")(prob)\n",
    "    prob = Reshape((-1,2),name=f\"{name}_prob\")(prob)\n",
    "\n",
    "    box = Conv2D(k*4,1,padding=\"same\",name=f\"box_conv_{name}\")(_in)\n",
    "    box = BatchNormalization(name=f\"box_batch_{name}\")(box)\n",
    "    box = Activation(\"sigmoid\",name=f\"box_out_{name}\")(box)\n",
    "    box = Reshape((-1,4),name=f\"{name}_box\")(box)\n",
    "    \n",
    "    return prob,box\n",
    "\n",
    "a = block(_inp,32,5,name=\"a\",pool=True)\n",
    "b = block(a,32,3,name=\"b\",pool=True)\n",
    "c = block(b,32,3,name=\"c\",pool=True)\n",
    "d = block(c,32,3,name=\"d\",pool=True)\n",
    "\n",
    "\n",
    "fpn0  = block(filters=64,ksize=3,_in=d,pool=True,name=\"FPN0\") ### 12x12x256\n",
    "(prob_0,box_0) = out(fpn0,3,\"fpn0\")\n",
    "\n",
    "fpn1  = block(filters=256,ksize=3,_in=fpn0,pool=True,name=\"FPN1\") ### 6x6x1024\n",
    "(prob_1,box_1) = out(fpn1,4,\"fpn1\")\n",
    "\n",
    "fpn2  = block(filters=1024,ksize=3,_in=fpn1,pool=True,name=\"FPN2\") ### 3x3x4096\n",
    "(prob_2,box_2) = out(fpn2,3,\"fpn2\")\n",
    "\n",
    "prob_out = concatenate([prob_0,prob_1,prob_2],1,name=\"prob\")\n",
    "box_out = concatenate([box_0,box_1,box_2],1,name=\"box\")\n",
    "\n",
    "net = keras.Model(_inp,[prob_out,box_out])\n",
    "prob_train = keras.Model(_inp,prob_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "net.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = np.random.randint(0,len(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "a = net(images[i:i+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p,b = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.shape,b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_crossentropy = tf.keras.losses.BinaryCrossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BoxLoss(tf.Module):\n",
    "    \"\"\"\n",
    "    BoxLoss\n",
    "    \"\"\"\n",
    "    def __init__(self,):\n",
    "        self.__name__=\"BoxLoss\"\n",
    "        self.zero = tf.constant(0,tf.float32)\n",
    "        self.one = tf.constant(1,tf.float32)\n",
    "        self.two = tf.constant(2,tf.float32)\n",
    "        self.l2_loss = tf.keras.losses.MeanSquaredError()\n",
    "\n",
    "        self.slice_y = {\"begin\":[0,0,0],\"size\":[-1,-1,1]}\n",
    "        self.slice_x = {\"begin\":[0,0,1],\"size\":[-1,-1,1]}\n",
    "        self.slice_h = {\"begin\":[0,0,2],\"size\":[-1,-1,1]}\n",
    "        self.slice_w = {\"begin\":[0,0,3],\"size\":[-1,-1,1]}\n",
    "        \n",
    "        self.repr = f\"\"\"\n",
    "BoxLoss(\n",
    "    \n",
    ")\n",
    "        \"\"\"\n",
    "        \n",
    "    def __repr__(self,):\n",
    "        return self.repr\n",
    "\n",
    "    \n",
    "    @tf.function\n",
    "    def __call__(self,y_true,y_pred,*args,**kwargs):\n",
    "        \n",
    "        y = tf.slice(y_true,**self.slice_y)\n",
    "        x = tf.slice(y_true,**self.slice_x)\n",
    "\n",
    "        mask = tf.logical_or(tf.greater(y,self.zero),tf.greater(x,self.zero))\n",
    "\n",
    "        y = y[mask] \n",
    "        x = x[mask] \n",
    "        h = tf.slice(y_true,**self.slice_h)[mask] \n",
    "        w = tf.slice(y_true,**self.slice_w)[mask] \n",
    "\n",
    "        y_ = tf.slice(y_pred,**self.slice_y)[mask] \n",
    "        x_ = tf.slice(y_pred,**self.slice_x)[mask] \n",
    "        h_ = tf.slice(y_pred,**self.slice_h)[mask] \n",
    "        w_ = tf.slice(y_pred,**self.slice_w)[mask] \n",
    "        \n",
    "        w2  = tf.divide(w,self.two)\n",
    "        h2  = tf.divide(h,self.two)\n",
    "        w2_  = tf.divide(w_,self.two)\n",
    "        h2_  = tf.divide(h_,self.two)\n",
    "        \n",
    "        xmin = tf.subtract(x,w2)\n",
    "        xmax = tf.add(x,w2)\n",
    "        ymin = tf.subtract(y,h2)\n",
    "        ymax = tf.add(y,h2)\n",
    "        \n",
    "        xmin_ = tf.subtract(x_,w2_)\n",
    "        xmax_ = tf.add(x_,w2_)\n",
    "        ymin_ = tf.subtract(y_,h2_)\n",
    "        ymax_ = tf.add(y_,h2_)\n",
    "        \n",
    "        Cymin = tf.maximum(ymin,ymin_)\n",
    "        Cymax = tf.minimum(ymax,ymax_)\n",
    "        Cxmin = tf.maximum(xmin,xmin_)\n",
    "        Cxmax = tf.minimum(xmax,xmax_)\n",
    "\n",
    "        Ch = tf.subtract(Cymax , Cymin)\n",
    "        Cw = tf.subtract(Cxmax , Cxmin)\n",
    "        \n",
    "        Aa = tf.multiply( h , w )\n",
    "        Ba = tf.multiply( h_ , w_ )\n",
    "        Ca = tf.multiply( Cw , Ch )\n",
    "        \n",
    "        IoU = tf.reduce_mean(tf.subtract(self.one,tf.divide(Ca,tf.subtract(tf.add(Aa,Ba),Ca))))\n",
    "        Xl2 = self.l2_loss(x,x_)\n",
    "        Yl2 = self.l2_loss(y,y_)\n",
    "        \n",
    "        return Xl2 + Yl2 + IoU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxloss = BoxLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def schedule(epoch):\n",
    "    if epoch > 100:\n",
    "        return .000001\n",
    "    elif epoch > 70:\n",
    "        return .00001\n",
    "    elif epoch > 10:\n",
    "        return .0001\n",
    "    else:\n",
    "        return .001\n",
    "    \n",
    "lrs = LearningRateScheduler(schedule=schedule,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chk = ModelCheckpoint(filepath=\"./checkpoints/net\",save_weights_only=True,monitor='loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flow(epochs,index):\n",
    "    for epoch in range(epochs):\n",
    "        for i in train_index:\n",
    "            yield images[i:i+1],(y_prob[i:i+1],y_box[i:i+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_flow = flow(120,train_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "net.compile(optimizer=opt,loss={\"prob\":binary_crossentropy,\"box\":boxloss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "net.fit_generator(train_flow,steps_per_epoch=len(train_index),epochs=120,callbacks=[chk,lrs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = np.random.choice(test_index)\n",
    "img = images[i].copy()\n",
    "pa,ba = net.predict(img.reshape(1,IMG_SIZE,IMG_SIZE,3))\n",
    "pa = prob_train.predict(img.reshape(1,IMG_SIZE,IMG_SIZE,3))\n",
    "decoded = anchors.decode(pa,ba,thresh=0.5)\n",
    "\n",
    "for y,x,h,w in decoded:\n",
    "    xmin,ymin,xmax,ymax = x - (w//2),y - (h//2),x + (w//2),y + (h//2)\n",
    "    img = cv2.circle(img,(x,y),2,(255,255,0),-1)\n",
    "    img = cv2.rectangle(img,(xmin,ymin),(xmax,ymax),(255,0,0),1)    \n",
    "\n",
    "plt.figure(figsize=(14,14))\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
